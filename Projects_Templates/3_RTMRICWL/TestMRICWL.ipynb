{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replaying Old Data\n",
    "\n",
    "- Work under a separate branch with git (i.e. git checkout -b my-new-branch)\n",
    "\n",
    "- Make a new folder in Projects (for your specific purposes)\n",
    "\n",
    "- Copy this ipynb file that folder\n",
    "\n",
    "- The data is stored on L-Drive\n",
    "\n",
    "- the main gist of re-playing existing data is:\n",
    "    - that your first load everything into a big matrix with mne\n",
    "    - then initialize a specific **amp** (i.e., the \"replayamp\")\n",
    "    - then do exactly the same as normal, with a while True loop with calls to amp.get_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the needed stuff:\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import easygui  # popup windows with buttons made easy\n",
    "import mne  # EEGLAB for python\n",
    "from IPython.display import clear_output  # to clear the cell output during while loop\n",
    "import re  # regular expressions\n",
    "import pickle  # to save/load data\n",
    "import dynarray  # a growing numpy array\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "sys.path.append(\"../../mushu\")  # driver for the amps\n",
    "sys.path.append(\"../../mushu/libmushu\")\n",
    "import libmushu\n",
    "\n",
    "sys.path.append(\"../../nftools\")  # handy stuff needed for NF\n",
    "from nftools.loopcontrol import LoopState\n",
    "from nftools.analysis import convert_alld_allm_to_mne\n",
    "from nftools.analysis import select_part_from_mne_dataset\n",
    "from nftools.analysis import plot_compare_two_spectra\n",
    "\n",
    "\n",
    "sys.path.append(\"../../wyrm\")  # real-time data analysis\n",
    "from wyrm.types import RingBuffer\n",
    "from wyrm.types import BlockBuffer\n",
    "from wyrm import io\n",
    "from wyrm import processing as proc\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "from collections import deque  # a FILO list useful for plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_data_for_mri_cwl_development.set\n",
      "The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n",
      "The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "Events like the following will be dropped entirely: ['Sync On', 'boundary'], 2 in total\n",
      "42/120 event codes could not be mapped to integers. Use the 'event_id' parameter to map such events manually.\n",
      "24 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.\n",
      "Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-7b3ae74325da>:8: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "<ipython-input-2-7b3ae74325da>:8: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "<ipython-input-2-7b3ae74325da>:8: RuntimeWarning: Events like the following will be dropped entirely: ['Sync On', 'boundary'], 2 in total\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "<ipython-input-2-7b3ae74325da>:8: RuntimeWarning: 42/120 event codes could not be mapped to integers. Use the 'event_id' parameter to map such events manually.\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "<ipython-input-2-7b3ae74325da>:8: RuntimeWarning: 24 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
      "<ipython-input-2-7b3ae74325da>:8: RuntimeWarning: Data will be preloaded. preload=False or a string preload is not supported when the data is stored in the .set file\n",
      "  raw_fromfile = mne.io.read_raw_eeglab(fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-7b3ae74325da>:10: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n",
      "  raw_fromfile.set_montage(montage)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawEEGLAB  |  None, n_channels x n_times : 39 x 400001 (80.0 sec), ~119.1 MB, data loaded>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the replay notebook - so select a file for playback - this is for eeglab files.\n",
    "\n",
    "#fn=easygui.fileopenbox(default='*.set')\n",
    "fn='trial_data_for_mri_cwl_development.set'\n",
    "#fn='trio2_eoec_outside_before.set'\n",
    "print(fn)\n",
    "\n",
    "raw_fromfile = mne.io.read_raw_eeglab(fn)\n",
    "montage=mne.channels.read_montage('standard_1005', ch_names=raw_fromfile.ch_names)  # always use MNE definitions\n",
    "raw_fromfile.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties of the recording, and what we're doing here:\n",
    "fs = raw_fromfile.info['sfreq']\n",
    "nbchan = raw_fromfile.info['nchan']-1\n",
    "\n",
    "updateTime = 0.1  # run some kind of calculation every X seconds\n",
    "buffSize = 1.0  # run calculation on last X seconds of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5  \n",
    "plt.ion()  # enable widget plots & interactive plots\n",
    "\n",
    "time_in_plot=2.0\n",
    "sy1=deque(np.zeros(round(fs * time_in_plot)), round(fs * time_in_plot))  # for plotting - the FILO list\n",
    "sy2=deque(np.zeros(round(fs * time_in_plot)), round(fs * time_in_plot))  # for plotting - the FILO list\n",
    "\n",
    "channel_to_plot=10\n",
    "sx = np.linspace(0, time_in_plot, round(fs * time_in_plot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real-time data filtering -- high-pass filter (of 1.0 Hz)\n",
    "\n",
    "f_low = 1.0\n",
    "# f_high = 15.0\n",
    "butter_ord = 3\n",
    "lenchannels = nbchan\n",
    "\n",
    "#rt_b, rt_a = signal.butter(butter_ord, [f_low / fn, f_high / fn], btype='band')\n",
    "rt_b_hp, rt_a_hp = signal.butter(butter_ord, 2*f_low/fs, btype='high', analog=False)  # a digital high-pass filter\n",
    "rt_zi_hp = proc.lfilter_zi(rt_b_hp, rt_a_hp, lenchannels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real-time data filtering -- band-pass filter (of 12.0 - 15.0 Hz)\n",
    "\n",
    "f_low = 12.0\n",
    "f_high = 15.0\n",
    "butter_ord = 3\n",
    "lenchannels = nbchan\n",
    "\n",
    "#rt_b, rt_a = signal.butter(butter_ord, [f_low / fn, f_high / fn], btype='band')\n",
    "rt_b_bp, rt_a_bp = signal.butter(butter_ord, [2*f_low/fs, 2*f_high/fs], btype='band', analog=False)  # a digital high-pass filter\n",
    "rt_zi_bp = proc.lfilter_zi(rt_b_bp, rt_a_bp, lenchannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for replay (warning: need probably a lot of memory)\n",
    "\n",
    "mul_factor = 1.0\n",
    "if 1e-6 in [raw_fromfile.info['chs'][0]['cal'], raw_fromfile.info['chs'][0]['range']]:\n",
    "    mul_factor = 1.0 / 1e-6\n",
    "\n",
    "seed_d=raw_fromfile[:-1,:][0] * mul_factor  # scale the data to seed (so no 1e-6 stuff in the replayed data)\n",
    "seed_d=np.array(seed_d.transpose())\n",
    "seed_ch=raw_fromfile.ch_names[0:-1]\n",
    "seed_fs=raw_fromfile.info['sfreq']\n",
    "\n",
    "# prepare for replay; markers:\n",
    "seed_mdata=np.transpose(raw_fromfile[-1,:][0])\n",
    "seed_m=[[i / raw_fromfile.info['sfreq'] * 1000, int(m[0])] for i, m in enumerate(seed_mdata) if m > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = libmushu.get_amp('replayamp')\n",
    "amp.configure(seed_d, seed_m, seed_ch, seed_fs, realtime=True, blocksize_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alld=dynarray.DynamicArray((None, len(amp.get_channels())))     # data\n",
    "allm=[]     # markers\n",
    "sfreq = amp.get_sampling_frequency()  # sampling frequency\n",
    "ch_names=amp.get_channels()  # channel names\n",
    "\n",
    "markTime=time.time()\n",
    "\n",
    "\n",
    "rb = RingBuffer(buffSize * 1000)  # the buffer containing the last X seconds of data - declared in MILISECONDS\n",
    "totalTime = seed_d.shape[0]/raw_fromfile.info['sfreq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()  # plotting...\n",
    "th=fig.suptitle('')\n",
    "ah1=fig.add_subplot(121)\n",
    "ah2=fig.add_subplot(122)\n",
    "l1, = ah1.plot(sx, sy1)\n",
    "l2, = ah2.plot(sx, sy2)\n",
    "\n",
    "\n",
    "\n",
    "# l=LoopState(); l.start()\n",
    "markeroffset = 0  # needed to store all data in one big mat/vector\n",
    "t0=time.time()\n",
    "curTime=time.time()\n",
    "st=''\n",
    "while curTime - t0 < totalTime:  # l.get_state() != 'Stop':\n",
    "   \n",
    "    \n",
    "    # keep track of time:\n",
    "    curTime = time.time()\n",
    "    \n",
    "    # this is where you get the data\n",
    "    data, marker = amp.get_data()\n",
    "    \n",
    "\n",
    "    \n",
    "    if data.shape[0] > 0:  # this is crucial for remembering filter state.\n",
    "\n",
    "        dataf, rt_zi_bp = signal.lfilter(rt_b_bp, rt_a_bp, data, axis=0, zi=rt_zi_bp)  # how to operate directly on the data\n",
    "        \n",
    "        cnt = io.convert_mushu_data(data, marker, sfreq, ch_names)\n",
    "        f_cnt = cnt # io.convert_mushu_data(dataf, marker, sfreq, ch_names)\n",
    "\n",
    "        # f_cnt, rt_zi_bp = proc.lfilter(cnt, rt_b_bp, rt_a_bp, zi=rt_zi_bp)  # real-time data preprocessing...\n",
    "\n",
    "        # plotting...\n",
    "        sy1.extend(cnt.data[:,channel_to_plot])  # to visualize/plot -- s1 and s2 are deque's\n",
    "        sy2.extend(f_cnt.data[:,channel_to_plot])\n",
    "        l1.set_ydata(sy1)\n",
    "        l2.set_ydata(sy2)\n",
    "        msy1=np.mean(sy1)\n",
    "        msy2=np.mean(sy2)\n",
    "        ah1.set_ylim(-5000+msy1, 5000+msy1)\n",
    "        ah2.set_ylim(-100+msy2, 100+msy2)\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        \n",
    "        # currently has no purpose\n",
    "        newsamples = cnt.data.shape[0]\n",
    "\n",
    "        # append to ringbuffer, so we can calculate features later on on the last N secs/samples of data.\n",
    "        rb.append(f_cnt)\n",
    "\n",
    "        # append it to the big matrix, for saving later on with pickle.\n",
    "        alld.extend(data)\n",
    "        for m in marker:\n",
    "            allm.append([m[0] + markeroffset, m[1]])\n",
    "        markeroffset += newsamples / float(sfreq) * 1000.\n",
    "        \n",
    "\n",
    "\n",
    "        # do the following every 0.1 msec - with with the ringbuffer:\n",
    "        if curTime - markTime > updateTime:\n",
    "            # do Stuff\n",
    "\n",
    "            markTime = curTime\n",
    "            # 1) obtain last 1-second(s)\n",
    "            d = rb.get()\n",
    "\n",
    "            \n",
    "\n",
    "            # clear_output(wait=True)  # write some logging information here\n",
    "            # clear_output clear the output of the cell, but if you do that you also remove the figures, it seems\n",
    "            # so don't do it!\n",
    "            str1 = 'Playing Back - time = %f' % (curTime - t0)\n",
    "            str2 = 'Length Markers: %d' % len(allm)\n",
    "            str3 = '%d, %d' % data.shape\n",
    "            #str4 = 'Feature Value: %f' % feature\n",
    "            #str5 = 'Scaled Signal for NF: %f' % signalToSend\n",
    "            #print(str1 + '\\n' + str2 + '\\n' + str3 + '\\n' + str4 + '\\n' + str5)\n",
    "            \n",
    "            # print('Length Markers: %d' % len(allm))\n",
    "            # print(data.shape)\n",
    "            th.set_text(str1 + '\\n' + str2 + '\\n' +str3)\n",
    "            #featureth.set_text(str4 + '\\n' + str5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amplifier stopped!\n"
     ]
    }
   ],
   "source": [
    "amp.stop()\n",
    "alld.shrink_to_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to disk, so we can re-load it later:\n",
    "\n",
    "t={'alld':alld, 'allm':allm, 'ch_names':ch_names, 'sfreq':sfreq}\n",
    "with open('c-allm-and-alld.pkl', 'wb') as f:\n",
    "    pickle.dump(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk:\n",
    "\n",
    "with open('c-allm-and-alld.pkl','rb') as f:\n",
    "    t=pickle.load(f)\n",
    "for key in t.keys():\n",
    "    locals()[key] = t[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../nftools/nftools/analysis.py:31: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['EOG', 'ECG', 'CW1', 'CW2', 'CW3', 'CW4', 'CW5', 'CW6']. Their position has been left untouched.\n",
      "  montage=montage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=38, n_times=400001\n",
      "    Range : 0 ... 400000 =      0.000 ...    80.000 secs\n",
      "Ready.\n",
      "5000.0\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=400001\n",
      "    Range : 0 ... 400000 =      0.000 ...    80.000 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "raw = convert_alld_allm_to_mne(alld, allm, ch_names, sfreq)  # covert to MNE\n",
    "# raw.resample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RawArray  |  None, n_channels x n_times : 39 x 400001 (80.0 sec), ~119.1 MB, data loaded>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot(scalings='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw.set_eeg_reference(ref_channels='average')\n",
    "# better not (yet) - before removing bad channels, since these mess up your data big time: see PREP paper:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-stop filter\n",
      "Filter length of 33001 samples (6.600 sec) selected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawArray  |  None, n_channels x n_times : 39 x 400001 (80.0 sec), ~119.1 MB, data loaded>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False,\n",
    "                       stim=False, exclude='bads')\n",
    "\n",
    "raw.notch_filter(np.arange(50, 300, 50), picks=picks, filter_length='auto', phase='zero')\n",
    "# add it (potentialy) some other preprocessing steps here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.638 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims, initial)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/mne/viz/evoked.py:162: RuntimeWarning: invalid value encountered in maximum\n",
      "  rgb /= np.maximum(rgb.max(0), 1e-16)  # avoid div by zero\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/matplotlib/colors.py:251: RuntimeWarning: invalid value encountered in less\n",
      "  if np.any((result < 0) | (result > 1)):\n",
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/matplotlib/colors.py:251: RuntimeWarning: invalid value encountered in greater\n",
      "  if np.any((result < 0) | (result > 1)):\n"
     ]
    }
   ],
   "source": [
    "raw.plot_psd(tmax=np.inf, fmax=1000, n_fft=2048*4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/.conda/envs/rt/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "mne.viz.plot_sensors(raw.info, show_names=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
